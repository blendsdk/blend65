/**
 * End-to-End Pipeline Validation Test
 * Tests the complete Blend65 compilation pipeline on real source code
 */

import { readFileSync } from 'fs';
import { join } from 'path';

// Import all pipeline components
import { Blend65Lexer } from './packages/lexer/src/index.js';
import { Blend65Parser } from './packages/parser/src/index.js';
import { SemanticAnalyzer } from './packages/semantic/src/index.js';
import {
  ASTToILTransformer,
  ILOptimizationFramework,
  createDefaultPatternRegistry,
} from './packages/il/src/index.js';

/**
 * Test complete pipeline on v0.2 game example
 */
async function testCompletePipeline() {
  console.log('üöÄ Testing Complete Blend65 Pipeline...\n');

  try {
    // Step 1: Load real Blend65 source code
    console.log('üìÅ Loading v0.2 game example...');
    const sourceCode = readFileSync(
      join(process.cwd(), 'examples/v02-complete-game-example.blend'),
      'utf8'
    );
    console.log(`   Source: ${sourceCode.split('\n').length} lines loaded\n`);

    // Step 2: Lexical analysis
    console.log('üî§ Step 1: Lexical Analysis...');
    const lexer = new Blend65Lexer(sourceCode);
    const tokens = lexer.tokenize();

    if (!tokens.success) {
      throw new Error(`Lexer failed: ${tokens.errors.map(e => e.message).join(', ')}`);
    }

    console.log(`   ‚úÖ ${tokens.data.length} tokens generated`);
    console.log(`   üìä Keywords: ${tokens.data.filter(t => t.type === 'KEYWORD').length}`);
    console.log(`   üìä Identifiers: ${tokens.data.filter(t => t.type === 'IDENTIFIER').length}`);
    console.log(
      `   üìä Literals: ${tokens.data.filter(t => t.type === 'NUMBER' || t.type === 'STRING').length}\n`
    );

    // Step 3: Syntax analysis
    console.log('üå≥ Step 2: Syntax Analysis...');
    const parser = new Blend65Parser(tokens.data);
    const ast = parser.parse();

    if (!ast.success) {
      throw new Error(`Parser failed: ${ast.errors.map(e => e.message).join(', ')}`);
    }

    console.log(`   ‚úÖ AST generated successfully`);
    console.log(`   üìä Module: ${ast.data.module?.name || 'unnamed'}`);
    console.log(`   üìä Imports: ${ast.data.imports.length}`);
    console.log(
      `   üìä Functions: ${ast.data.body.filter(d => d.kind === 'FunctionDeclaration').length}`
    );
    console.log(`   üìä Enums: ${ast.data.body.filter(d => d.kind === 'EnumDeclaration').length}`);
    console.log(
      `   üìä Variables: ${ast.data.body.filter(d => d.kind === 'VariableDeclaration').length}\n`
    );

    // Step 4: Semantic analysis
    console.log('üß† Step 3: Semantic Analysis...');
    const semanticAnalyzer = new SemanticAnalyzer();
    const semanticResult = semanticAnalyzer.analyzeProgram([ast.data]);

    if (!semanticResult.success) {
      throw new Error(
        `Semantic analysis failed: ${semanticResult.errors.map(e => e.message).join(', ')}`
      );
    }

    console.log(`   ‚úÖ Semantic analysis completed`);
    console.log(`   üìä Symbols: ${semanticResult.data.globalSymbolTable.getSymbolCount()}`);
    console.log(`   üìä Modules: ${semanticResult.data.moduleAnalysis.length}`);
    console.log(`   üìä Functions: ${semanticResult.data.functionAnalysis.length}`);
    console.log(`   üìä Variables: ${semanticResult.data.variableAnalysis.length}\n`);

    // Step 5: IL transformation
    console.log('‚öôÔ∏è  Step 4: IL Transformation...');
    const ilTransformer = new ASTToILTransformer();
    const ilResult = ilTransformer.transformProgram(
      ast.data,
      semanticResult.data.globalSymbolTable,
      semanticResult.data
    );

    if (!ilResult.success) {
      throw new Error(
        `IL transformation failed: ${ilResult.errors.map(e => e.message).join(', ')}`
      );
    }

    console.log(`   ‚úÖ IL transformation completed`);
    console.log(`   üìä Modules: ${ilResult.data.modules.length}`);
    console.log(
      `   üìä Functions: ${ilResult.data.modules.reduce((total, m) => total + m.functions.length, 0)}`
    );
    console.log(
      `   üìä Instructions: ${ilResult.data.modules.reduce(
        (total, m) => total + m.functions.reduce((ftotal, f) => ftotal + f.instructions.length, 0),
        0
      )}\n`
    );

    // Step 6: IL optimization
    console.log('‚ö° Step 5: IL Optimization...');
    const patternRegistry = createDefaultPatternRegistry();
    const optimizer = new ILOptimizationFramework(patternRegistry);
    const optimizationResult = await optimizer.optimizeProgram(ilResult.data);

    console.log(`   ‚úÖ IL optimization completed`);
    console.log(`   üìä Patterns Applied: ${optimizationResult.metrics.patternsApplied}`);
    console.log(`   üìä Cycles Saved: ${optimizationResult.metrics.totalCyclesSaved}`);
    console.log(`   üìä Performance Grade: ${optimizationResult.performanceGrade}`);
    console.log(`   üìä Optimization Time: ${optimizationResult.metrics.optimizationTime}ms\n`);

    // Summary
    console.log('üéâ COMPLETE PIPELINE SUCCESS!');
    console.log('‚úÖ All phases completed without errors');
    console.log('‚úÖ Real Blend65 source code fully processed');
    console.log('‚úÖ Optimization framework operational');
    console.log('‚úÖ Ready for code generation phase\n');

    return {
      success: true,
      tokens: tokens.data.length,
      astNodes: countASTNodes(ast.data),
      symbols: semanticResult.data.globalSymbolTable.getSymbolCount(),
      ilInstructions: ilResult.data.modules.reduce(
        (total, m) => total + m.functions.reduce((ftotal, f) => ftotal + f.instructions.length, 0),
        0
      ),
      patternsApplied: optimizationResult.metrics.patternsApplied,
      optimizationGrade: optimizationResult.performanceGrade,
    };
  } catch (error) {
    console.error('‚ùå Pipeline test failed:', error);
    return { success: false, error: error.message };
  }
}

function countASTNodes(ast: any): number {
  // Simple recursive node counter
  let count = 1;
  for (const key in ast) {
    if (ast[key] && typeof ast[key] === 'object') {
      if (Array.isArray(ast[key])) {
        count += ast[key].reduce((sum: number, item: any) => sum + countASTNodes(item), 0);
      } else {
        count += countASTNodes(ast[key]);
      }
    }
  }
  return count;
}

// Run the test
testCompletePipeline()
  .then(result => {
    if (result.success) {
      console.log('üéØ PIPELINE VALIDATION COMPLETE');
      console.log(`üìä Final Metrics:`);
      console.log(`   - Tokens: ${result.tokens}`);
      console.log(`   - AST Nodes: ${result.astNodes}`);
      console.log(`   - Symbols: ${result.symbols}`);
      console.log(`   - IL Instructions: ${result.ilInstructions}`);
      console.log(`   - Optimization Patterns: ${result.patternsApplied}`);
      console.log(`   - Performance Grade: ${result.optimizationGrade}`);
      console.log('\nüöÄ READY FOR PHASE 3: CODE GENERATION');
    } else {
      console.error('‚ùå Pipeline validation failed');
      process.exit(1);
    }
  })
  .catch(error => {
    console.error('‚ùå Test execution failed:', error);
    process.exit(1);
  });
